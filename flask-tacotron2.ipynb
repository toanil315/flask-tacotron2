{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install flask-ngrok","metadata":{"id":"kx6XQ3KW4DWh","outputId":"9acb8589-7fb7-4bf6-9a99-febf3c377718","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install Flask","metadata":{"id":"gL2wuxd0-LVI","outputId":"8dafdcf4-f6dd-470f-feb6-b6a8fa3e9ba1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/NVIDIA/apex\n!cd apex\n!pip install -v --no-cache-dir  /kaggle/working/apex","metadata":{"id":"E2bL5keZ2vm9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile requirements.txt\nmatplotlib==2.1.0\ninflect==0.2.5\nUnidecode==1.0.22\npillow\ntensorflow==1.15.2\nlibrosa==0.8.1\nnumba==0.48.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -r requirements.txt --user","metadata":{"id":"dBrlxm_5200U","outputId":"ff07dd20-9c33-4f80-dcf4-01b2d179f5d7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pyngrok==4.1.1\n!ngrok authtoken '281CNui5X6FuaLQ6hPCRMcVBTjr_48bsTy1xokX5ubxn3n2u3'\n!pip install SoundFile","metadata":{"id":"8q62k1YWRhT0","outputId":"7accdf6c-5569-45fe-d833-1862b188779b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/input/datasettacotron2flask/flask","metadata":{"execution":{"iopub.status.busy":"2022-04-21T12:36:39.457081Z","iopub.execute_input":"2022-04-21T12:36:39.457732Z","iopub.status.idle":"2022-04-21T12:36:39.484382Z","shell.execute_reply.started":"2022-04-21T12:36:39.457645Z","shell.execute_reply":"2022-04-21T12:36:39.483668Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from flask import Flask , request\nfrom flask_ngrok import run_with_ngrok\nfrom pyngrok import ngrok\n# from helper import load_model , tts , pts\nimport matplotlib\n%matplotlib inline\nimport matplotlib.pylab as plt\nimport numpy as np\nimport torch\nimport librosa\nimport threading\nfrom hparams import create_hparams\nfrom model import Tacotron2\nfrom layers import TacotronSTFT, STFT\nfrom audio_processing import griffin_lim\nfrom train import load_model\nfrom text import text_to_sequence\nimport re\nimport sys\nsys.path.append('waveglow/')\n# matplotlib inline\nfrom denoiser import Denoiser\nfrom unicodedata import normalize\nfrom datetime import datetime\nimport soundfile as sf","metadata":{"id":"t-0CaRC924qG","execution":{"iopub.status.busy":"2022-04-21T12:36:52.097693Z","iopub.execute_input":"2022-04-21T12:36:52.097960Z","iopub.status.idle":"2022-04-21T12:36:56.390800Z","shell.execute_reply.started":"2022-04-21T12:36:52.097931Z","shell.execute_reply":"2022-04-21T12:36:56.388931Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"model = None\nhparams = None\nwaveglow = None\ndenoiser = None\nduration_of_char = 1574.5753424657535\n\napp = Flask(__name__)\nrun_with_ngrok(app) \n\n@app.route('/')\ndef index():\n\treturn '<h1>Hello World!</h1>'\n\n@app.route(\"/text2speech\", methods=[\"POST\"])\ndef text2speech():\n    if request.method == \"POST\":\n      now = datetime.now()\n      dt_string = now.strftime(\"%d-%m-%Y-%H:%M:%S\")\n      file_path = '/kaggle/working/audio_' + dt_string + '.wav'\n      data = request.get_json()\n      audio = pts(data[\"text\"])\n      sf.write('/kaggle/working/audio_' + dt_string + '.wav',audio.T, 22050)\n      return \"OK\"\n\ndef load_data():\n    global model \n    global hparams\n    global waveglow\n    global denoiser\n\n    hparams = create_hparams()\n    hparams.sampling_rate = 22050\n\n    checkpoint_path = \"/kaggle/input/datasettacotron2flask/flask/output_vi/checkpoint_421000\"\n    model = load_model(hparams)\n    model.load_state_dict(torch.load(checkpoint_path)['state_dict'])\n    _ = model.cuda().eval().half()\n\n    # waveglow_path = '/content/drive/MyDrive/flask/waveglow/waveglow_256channels_universal_v5.pt'\n    # waveglow = torch.load(waveglow_path)['model']\n    waveglow = torch.hub.load('nvidia/DeepLearningExamples:torchhub', 'nvidia_waveglow')\n    # waveglow_path = '/content/drive/MyDrive/Output/nvidia_waveglowpyt_fp32_20190427'\n    # ckpt = torch.load(waveglow_path)\n    # state_dict = ckpt['state_dict']\n    # config = ckpt['config']\n    # waveglow = WaveGlow(**config)\n    waveglow.cuda().eval().half()\n    for k in waveglow.convinv:\n        k.float()\n    denoiser = Denoiser(waveglow)\n\n\ndef tts(text):\n\ttext = normalize(\"NFC\", text).lower()\n\tsequence = np.array(text_to_sequence(text, ['basic_cleaners']))[None, :]\n\tsequence = torch.autograd.Variable(\n\t\ttorch.from_numpy(sequence)).cuda().long()\n\twith torch.no_grad():\n\t\tmel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n\t\taudio = waveglow.infer(mel_outputs_postnet, sigma=0.666)\n\taudio_denoised = denoiser(audio, strength=0.005)[:, 0].cpu().numpy()\n    \n\taudio_result = audio_denoised\n\tduration_expected = int(duration_of_char * len(text))\n\tif (abs(np.size(audio_denoised) - duration_expected) / duration_expected) > 0.25:\n\t\taudio_result = np.array([audio_denoised[0][:int(duration_expected)]])\n    \n\treturn audio_result\n\n\ndef pts(para):\n\taudio = np.zeros((1,0))\n\tsentence_ls = para.split(\".\")\n\tfor sen in sentence_ls:\n\t\tsub_stn_ls = re.split(\",|;|-|:\", sen)\n\t\tfor sub_stn in sub_stn_ls:\n\t\t\taudio = np.append(audio, tts(sub_stn), axis=1)\n\t\t\taudio = np.append(audio, np.zeros((1, int(hparams.sampling_rate/8)), dtype=np.uint8) , axis=1)\n\t\taudio = np.append(audio, np.zeros((1, int(hparams.sampling_rate/4)), dtype=np.uint8) , axis=1)\n\treturn audio\n\nload_data()\nprint(model)\napp.run()","metadata":{"id":"3DeSweHa8MsC","outputId":"ef950ae0-98b5-43da-9fec-bb2cd22ed6a3","execution":{"iopub.status.busy":"2022-04-21T13:38:26.194467Z","iopub.execute_input":"2022-04-21T13:38:26.195043Z","iopub.status.idle":"2022-04-21T13:51:30.403291Z","shell.execute_reply.started":"2022-04-21T13:38:26.195005Z","shell.execute_reply":"2022-04-21T13:51:30.402311Z"},"trusted":true},"execution_count":30,"outputs":[]}]}